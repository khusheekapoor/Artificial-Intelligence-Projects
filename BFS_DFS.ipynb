{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Week 3 - AI Lab\n",
        "\n",
        "Author: Khushee Kapoor\n",
        "\n",
        "Registration Number: 200968052"
      ],
      "metadata": {
        "id": "8-UaciI1DP7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up by importing the required libraries."
      ],
      "metadata": {
        "id": "1KqQ8nksDWwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the libraries\n",
        "import csv\n",
        "import sys\n",
        "import time"
      ],
      "metadata": {
        "id": "XwZW0g2GptgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this week's task, we have been given three datasets:\n",
        "- people: actors mapped to unique IDs with their birth years\n",
        "- movies: movies mapped to unique IDs\n",
        "- stars: actors and movies mapped together basis their unique IDs\n",
        "\n",
        "We model the above datasets as a Graph, with each actor being a Node, and the Edges representing the movies in which the actors have starred."
      ],
      "metadata": {
        "id": "k2Xfd1DIDycy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To assign the actors to Nodes in the graph, we create a class called Node."
      ],
      "metadata": {
        "id": "NoBQN-C5FJVb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6uMZW82lxlM"
      },
      "outputs": [],
      "source": [
        "# intializing the Node class\n",
        "class Node():\n",
        "    def __init__(self, state, parent, action):\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.action = action"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To employ searching techniques in the Graph modelled, we use Depth First Search and Breadth First Search. For the mentioned techniques, we will use the Stack and Queue data structures. Below we have created classes with functions for the same."
      ],
      "metadata": {
        "id": "mlQuU696FTp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stack class for depth first search\n",
        "class StackFrontier():\n",
        "    def __init__(self):\n",
        "        self.frontier = []\n",
        "\n",
        "    def add(self, node):\n",
        "        self.frontier.append(node)\n",
        "\n",
        "    def contains_state(self, state):\n",
        "        return any(node.state == state for node in self.frontier)\n",
        "\n",
        "    def empty(self):\n",
        "        return len(self.frontier) == 0\n",
        "\n",
        "    def remove(self):\n",
        "        if self.empty():\n",
        "            raise Exception(\"empty frontier\")\n",
        "        else:\n",
        "            node = self.frontier[-1]\n",
        "            self.frontier = self.frontier[:-1]\n",
        "            return node"
      ],
      "metadata": {
        "id": "X2S2FsMHm2Qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# queue class for breadth first search\n",
        "class QueueFrontier(StackFrontier):\n",
        "\n",
        "    def remove(self):\n",
        "        if self.empty():\n",
        "            raise Exception(\"empty frontier\")\n",
        "        else:\n",
        "            node = self.frontier[0]\n",
        "            self.frontier = self.frontier[1:]\n",
        "            return node"
      ],
      "metadata": {
        "id": "GeNNfwhcm3nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we create dictionaries to store the content in the csv file."
      ],
      "metadata": {
        "id": "_bq8G-yzFrsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# maps names to a set of corresponding person_ids\n",
        "names = {}\n",
        "\n",
        "# maps person_ids to a dictionary of: name, birth, movies (a set of movie_ids)\n",
        "people = {}\n",
        "\n",
        "# maps movie_ids to a dictionary of: title, year, stars (a set of person_ids)\n",
        "movies = {}"
      ],
      "metadata": {
        "id": "wI9kYMx6m36X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fashion the graph, we determine the connecting edges between two nodes. If two actors have acted in the same movie, there is an edge between them. The below function makes a set of such edges represented as a tuple of movie ID and person ID for the passed person ID."
      ],
      "metadata": {
        "id": "XlGJkqO2FyVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# determining the neighbors of passed person ID\n",
        "def neighbors_for_person(person_id):\n",
        "    \"\"\"\n",
        "    Returns (movie_id, person_id) pairs for people\n",
        "    who starred with a given person.\n",
        "    \"\"\"\n",
        "    movie_ids = people[person_id][\"movies\"]\n",
        "    neighbors = set()\n",
        "    for movie_id in movie_ids:\n",
        "        for person_id in movies[movie_id][\"stars\"]:\n",
        "            neighbors.add((movie_id, person_id))\n",
        "    return neighbors"
      ],
      "metadata": {
        "id": "vrjNFTpZkbWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there are many actors with the same name, we make a function to resolve any unique ID ambiguities."
      ],
      "metadata": {
        "id": "aXZ8HBjLGT82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# resolving name ambiguities\n",
        "def person_id_for_name(name):\n",
        "    \"\"\"\n",
        "    Returns the IMDB id for a person's name,\n",
        "    resolving ambiguities as needed.\n",
        "    \"\"\"\n",
        "    person_ids = list(names.get(name.lower(), set()))\n",
        "    if len(person_ids) == 0:\n",
        "        return None\n",
        "    elif len(person_ids) > 1:\n",
        "        print(f\"Which '{name}'?\")\n",
        "        for person_id in person_ids:\n",
        "            person = people[person_id]\n",
        "            name = person[\"name\"]\n",
        "            birth = person[\"birth\"]\n",
        "            print(f\"ID: {person_id}, Name: {name}, Birth: {birth}\")\n",
        "        try:\n",
        "            person_id = input(\"Intended Person ID: \")\n",
        "            if person_id in person_ids:\n",
        "                return person_id\n",
        "        except ValueError:\n",
        "            pass\n",
        "        return None\n",
        "    else:\n",
        "        return person_ids[0]"
      ],
      "metadata": {
        "id": "CkDYcC-fkeeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below function employs the searching techniques. \n",
        "\n",
        "Parameters:\n",
        "- method: DFS/ BFS\n",
        "- source: actor 1\n",
        "- target: actor 2\n",
        "\n",
        "The function uses the passed method to determine the appropriate data structure, and then finds the shortest path between the source and target provided."
      ],
      "metadata": {
        "id": "RiGDto0xGeju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the shortest path between the source and target\n",
        "def shortest_path(method, source, target):\n",
        "    \"\"\"\n",
        "    Returns the shortest list of (movie_id, person_id) pairs\n",
        "    that connect the source to the target.\n",
        "    If no possible path, returns None.\n",
        "    \"\"\"\n",
        "    solution_found = False\n",
        "    no_solution = False\n",
        "    solution = list()\n",
        "\n",
        "    initial = Node(state=source, parent=None, action=None)\n",
        "\n",
        "    if method=='bfs':\n",
        "      frontier = QueueFrontier()\n",
        "    if method=='dfs':\n",
        "      frontier = StackFrontier()\n",
        "    frontier.add(initial)\n",
        "    explored = set()\n",
        "    i = 0\n",
        "    while solution_found == False:\n",
        "\n",
        "        if frontier.empty() == True:\n",
        "            no_solution = True\n",
        "            solution_found = True\n",
        "        \n",
        "        node = frontier.remove()\n",
        "        # print(\"\\n\\nNode in= \",node, ' i=', i)\n",
        "\n",
        "        if node.state == target:\n",
        "            # Return the solution\n",
        "            solution_found = True\n",
        "            while node.parent is not None:\n",
        "                pid, mid = node.state, node.action\n",
        "                solution.append((mid, pid))\n",
        "                node = node.parent\n",
        "            solution.reverse()\n",
        "\n",
        "        explored.add(node)\n",
        "        children = neighbors_for_person(node.state)\n",
        "        for child in children:\n",
        "            child_node = Node(state=child[1], action=child[0],parent=node)\n",
        "            frontier.add(child_node)\n",
        "            if child_node.state == target:\n",
        "                # Return the solution\n",
        "                solution_found = True\n",
        "                while child_node.parent is not None:\n",
        "                    pid, mid = child_node.state, child_node.action\n",
        "                    solution.append((mid, pid))\n",
        "                    child_node = child_node.parent\n",
        "                solution.reverse()\n",
        "    \n",
        "    if solution_found == True:\n",
        "        if no_solution == True:\n",
        "            return None\n",
        "        return solution"
      ],
      "metadata": {
        "id": "bMH0vt3akRg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function below reads the content in the csv files and then converts it into a dictionary as requried by the other functions."
      ],
      "metadata": {
        "id": "B4vUnrD1mG81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the data to a dictionary\n",
        "def load_data(folder):\n",
        "    \"\"\"\n",
        "    Load data from CSV files into memory.\n",
        "    \"\"\"\n",
        "    # Load people\n",
        "    with open(f\"{folder}_people.csv\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            people[row[\"id\"]] = {\n",
        "                \"name\": row[\"name\"],\n",
        "                \"birth\": row[\"birth\"],\n",
        "                \"movies\": set()\n",
        "            }\n",
        "            if row[\"name\"].lower() not in names:\n",
        "                names[row[\"name\"].lower()] = {row[\"id\"]}\n",
        "            else:\n",
        "                names[row[\"name\"].lower()].add(row[\"id\"])\n",
        "\n",
        "    # Load movies\n",
        "    with open(f\"{folder}_movies.csv\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            movies[row[\"id\"]] = {\n",
        "                \"title\": row[\"title\"],\n",
        "                \"year\": row[\"year\"],\n",
        "                \"stars\": set()\n",
        "            }\n",
        "\n",
        "    # Load stars\n",
        "    with open(f\"{folder}_stars.csv\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            try:\n",
        "                people[row[\"person_id\"]][\"movies\"].add(row[\"movie_id\"])\n",
        "                movies[row[\"movie_id\"]][\"stars\"].add(row[\"person_id\"])\n",
        "            except KeyError:\n",
        "                pass"
      ],
      "metadata": {
        "id": "I2i_yxbXkwTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below function compiles all the above functions and calls them in the following sequence:\n",
        "- load_data: to convert the csv file into a dictionary\n",
        "- person_id_for_name: to resolve ambiguity of names\n",
        "- shortest_path: to find the shortest path between the source and target by using dfs/ bfs\n",
        "\n",
        "Apart from this, it takes in the following parameters:\n",
        "- folder: small/ large - we use small to test for ease\n",
        "- method: dfs/ bfs\n",
        "\n",
        "If a path between the two actors exists, then the degree of connection (number of edges between them) is printed alongwith the nodes (actors) and edges (movies) involved to establish the relationship."
      ],
      "metadata": {
        "id": "EYBEYTzMnZm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main function to compile the functions\n",
        "def main(folder, method):\n",
        "\n",
        "    # Load data from files into memory\n",
        "    print(\"Loading data...\")\n",
        "    load_data(folder)\n",
        "    print(\"Data loaded.\")\n",
        "\n",
        "    source = person_id_for_name(input(\"Enter Name: \"))\n",
        "    if source is None:\n",
        "        sys.exit(\"Person not found.\")\n",
        "    target = person_id_for_name(input(\"Enter Name: \"))\n",
        "    if target is None:\n",
        "        sys.exit(\"Person not found.\")\n",
        "\n",
        "    print(str.format('Using {}: ', method))\n",
        "\n",
        "    path = shortest_path(method, source, target)\n",
        "\n",
        "    if path is None:\n",
        "        print(\"Not connected.\")\n",
        "    else:\n",
        "        degrees = len(path)\n",
        "        print(f\"{degrees} degrees of separation.\")\n",
        "        path = [(None, source)] + path\n",
        "        for i in range(degrees):\n",
        "            person1 = people[path[i][1]][\"name\"]\n",
        "            person2 = people[path[i + 1][1]][\"name\"]\n",
        "            movie = movies[path[i + 1][0]][\"title\"]\n",
        "            print(f\"{i + 1}: {person1} and {person2} starred in {movie}\")"
      ],
      "metadata": {
        "id": "noJ_wPNZpoXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test out the functions, we use the 'small' dataset for ease. We first use 'bfs' method."
      ],
      "metadata": {
        "id": "LH_aRFS6oKvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "main('small', 'bfs')\n",
        "end = time.time()\n",
        "print(str.format('Elapsed time: {} seconds', end-start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkDJwdOUwYRb",
        "outputId": "b6adee57-fa37-4627-d7ea-13af40b64163"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Data loaded.\n",
            "Enter Name: Tom Hanks\n",
            "Enter Name: Cary Elwes\n",
            "Using bfs: \n",
            "2 degrees of separation.\n",
            "1: Tom Hanks and Robin Wright starred in Forrest Gump\n",
            "2: Robin Wright and Cary Elwes starred in The Princess Bride\n",
            "Elapsed time: 5.847280740737915 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the bfs method can find the solution very quick. When we tried to run the same combination using dfs, it ran for 30 minutes before the notebook got disconnected. Hence, to show dfs, we have used another example of 1 degree."
      ],
      "metadata": {
        "id": "PP3yQX_rtqV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "main('small', 'bfs')\n",
        "end = time.time()\n",
        "print(str.format('Elapsed time: {} seconds', end-start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrWy1hBuAbuq",
        "outputId": "6a0f626e-b772-4910-f72b-29db41bee9ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Data loaded.\n",
            "Enter Name: Tom Hanks\n",
            "Enter Name: Robin Wright\n",
            "Using bfs: \n",
            "1 degrees of separation.\n",
            "1: Tom Hanks and Robin Wright starred in Forrest Gump\n",
            "Elapsed time: 5.602598190307617 seconds\n"
          ]
        }
      ]
    }
  ]
}